name: Integration Tests

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * 1"  # Weekly on Mondays at 03:00 UTC

jobs:
  transcription-pipeline:
    strategy:
      fail-fast: false
      matrix:
        # Include both hosted and self-hosted runners
        # Windows self-hosted is optional/experimental for now, so we can comment it out or keep it if ready.
        # Based on requirements, we enable self-hosted.
        os: [ubuntu-latest, [self-hosted, linux], [self-hosted, windows]]
        
    runs-on: ${{ matrix.os }}
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        if: matrix.os == 'ubuntu-latest'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Run integration tests
        env:
          # Python handles forward slashes on all platforms
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python -m pytest tests/integration -m "not engine_smoke"

  engine-smoke-cpu:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Warm engine caches (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          # ReazonSpeech removed from CPU smoke due to ABI issues on hosted runners
          warm("whispers2t_base", "cpu", "en")
          PY

      - name: Run engine smoke tests (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          uv run python -m pytest tests/integration/engines -m "engine_smoke and not gpu"

  engine-smoke-gpu:
    if: vars.LIVECAP_ENABLE_GPU_SMOKE == '1'
    strategy:
      fail-fast: false
      matrix:
        os: [[self-hosted, linux], [self-hosted, windows]]

    runs-on: ${{ matrix.os }}

    env:
      LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
      LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python (Linux)
        if: runner.os == 'Linux'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Use preinstalled Python (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $python = Get-Command python3.12 | Select-Object -ExpandProperty Source
          if (-not $python) { throw "python3.12 not found on runner" }
          Write-Host "Using python at $python"
          "PYTHON_EXE=$python" | Out-File -FilePath $Env:GITHUB_ENV -Encoding utf8 -Append

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies (Linux)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          uv sync --extra translation --extra dev --extra engines-torch --extra engines-nemo

      - name: Sync dependencies (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          # Clean slate to avoid conflicts
          Remove-Item -Recurse -Force .venv -ErrorAction SilentlyContinue
          
          # Create venv explicitly
          uv python pin "$Env:PYTHON_EXE"
          uv venv
          
          # Add venv to PATH for subsequent steps
          echo "$PWD/.venv/Scripts" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
          
          # 1. Install CUDA-enabled PyTorch FIRST
          uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
          
          # 2. Install project dependencies using 'uv pip install'
          uv pip install -e .[translation,dev,engines-torch,engines-nemo]

      - name: Warm engine caches (GPU / self-hosted, Linux)
        if: runner.os == 'Linux'
        shell: bash
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          # ReazonSpeech disabled on Linux due to ABI issues
          warm("whispers2t_base", "cuda", "en")
          warm("parakeet", "cuda", "en")
          PY

      - name: Warm engine caches (GPU / self-hosted, Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          $script = @"
          import os
          import sys
          
          # Monkey-patch os.uname for Windows to satisfy lhotse dependency
          if sys.platform == "win32" and not hasattr(os, "uname"):
              from collections import namedtuple
              UnameResult = namedtuple("UnameResult", ["sysname", "nodename", "release", "version", "machine"])
              def uname():
                  # Avoid platform.* calls that might recurse back to os.uname
                  return UnameResult(
                      sysname="Windows",
                      nodename=os.environ.get("COMPUTERNAME", "unknown"),
                      release=os.environ.get("OS", "unknown"),
                      version="10.0.xxxx",
                      machine=os.environ.get("PROCESSOR_ARCHITECTURE", "AMD64")
                  )
              os.uname = uname

          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f'[{engine_type}/{device}] cached at: {models_dir}')

          warm('reazonspeech', 'cuda', 'ja')
          warm('whispers2t_base', 'cuda', 'en')
          warm('parakeet', 'cuda', 'en')
          "@
          
          $script | Out-File warmup.py -Encoding utf8
          # Use python directly
          python warmup.py

      - name: Run engine smoke tests (GPU / self-hosted, Linux)
        if: runner.os == 'Linux'
        shell: bash
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          # Skip ReazonSpeech on Linux GPU
          uv run python -m pytest tests/integration/engines -m "engine_smoke and gpu" -k "not reazonspeech" -v

      - name: Run engine smoke tests (GPU / self-hosted, Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          # Use python directly
          python -m pytest tests/integration/engines -m "engine_smoke and gpu" -v

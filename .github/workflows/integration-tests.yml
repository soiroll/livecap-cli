name: Integration Tests

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * 1"  # Weekly on Mondays at 03:00 UTC
  pull_request:
    paths:
      - 'engines/**'
      - 'livecap_core/**'
      - 'tests/integration/**'
      - 'pyproject.toml'
      - 'uv.lock'
      - '.github/workflows/integration-tests.yml'

jobs:
  transcription-pipeline:
    strategy:
      fail-fast: false
      matrix:
        # Include both hosted and self-hosted runners
        os: [ubuntu-latest, [self-hosted, linux], [self-hosted, windows]]
        
    runs-on: ${{ matrix.os }}
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        if: matrix.os == 'ubuntu-latest'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # Install libc++ for TenVAD on Ubuntu
      - name: Install libc++ (Ubuntu)
        if: matrix.os == 'ubuntu-latest'
        run: |
          sudo apt-get update
          sudo apt-get install -y libc++1

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      # Standard cache for hosted runners (Self-hosted optimization applied in engine-smoke-gpu)
      - name: Cache ffmpeg-bin
        if: matrix.os == 'ubuntu-latest'
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Configure Persistent Paths (Windows Self-hosted)
        if: contains(toJSON(matrix.os), 'windows') && contains(toJSON(matrix.os), 'self-hosted')
        shell: pwsh
        run: |
          $ffmpeg = "C:\LiveCap\Cache\ffmpeg-bin"
          New-Item -ItemType Directory -Force -Path $ffmpeg | Out-Null
          "LIVECAP_FFMPEG_BIN=$ffmpeg" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append

      - name: Configure Persistent Paths (Linux Self-hosted)
        if: contains(toJSON(matrix.os), 'linux') && contains(toJSON(matrix.os), 'self-hosted')
        shell: bash
        run: |
          ffmpeg="$HOME/LiveCap/Cache/ffmpeg-bin"
          mkdir -p "$ffmpeg"
          echo "LIVECAP_FFMPEG_BIN=$ffmpeg" >> $GITHUB_ENV

      - name: Check FFmpeg existence (Windows Self-hosted)
        if: contains(toJSON(matrix.os), 'windows') && contains(toJSON(matrix.os), 'self-hosted')
        id: check-ffmpeg-windows
        shell: pwsh
        run: |
          if (Test-Path "$Env:LIVECAP_FFMPEG_BIN\ffmpeg.exe") {
            echo "exists=true" | Out-File -FilePath $Env:GITHUB_OUTPUT -Encoding utf8 -Append
            Write-Host "FFmpeg found at $Env:LIVECAP_FFMPEG_BIN"
          } else {
            echo "exists=false" | Out-File -FilePath $Env:GITHUB_OUTPUT -Encoding utf8 -Append
            Write-Host "FFmpeg not found, triggering setup"
          }

      - name: Check FFmpeg existence (Linux Self-hosted)
        if: contains(toJSON(matrix.os), 'linux') && contains(toJSON(matrix.os), 'self-hosted')
        id: check-ffmpeg-linux
        shell: bash
        run: |
          if [ -f "$LIVECAP_FFMPEG_BIN/ffmpeg" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "FFmpeg found at $LIVECAP_FFMPEG_BIN"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "FFmpeg not found, triggering setup"
          fi

      - name: Setup LiveCap FFmpeg
        if: |
          matrix.os == 'ubuntu-latest' || 
          (contains(toJSON(matrix.os), 'linux') && steps.check-ffmpeg-linux.outputs.exists != 'true') || 
          (contains(toJSON(matrix.os), 'windows') && steps.check-ffmpeg-windows.outputs.exists != 'true')
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: ${{ env.LIVECAP_FFMPEG_BIN || 'ffmpeg-bin' }}

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Run integration tests
        env:
          # Python handles forward slashes on all platforms
          # Use persistent path if available, else relative path
          LIVECAP_FFMPEG_BIN: "${{ env.LIVECAP_FFMPEG_BIN || format('{0}/ffmpeg-bin', github.workspace) }}"
          # Enable realtime E2E tests on self-hosted runners only
          LIVECAP_ENABLE_REALTIME_E2E: ${{ contains(toJSON(matrix.os), 'self-hosted') && '1' || '' }}
        run: |
          uv run python -m pytest tests/integration -m "not engine_smoke"

  engine-smoke-cpu:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Warm engine caches (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          warm("whispers2t_base", "cpu", "en")
          PY

      - name: Run engine smoke tests (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          uv run python -m pytest tests/integration/engines -m "engine_smoke and not gpu"

  engine-smoke-gpu:
    if: vars.LIVECAP_ENABLE_GPU_SMOKE == '1'
    strategy:
      fail-fast: false
      matrix:
        os: [[self-hosted, linux], [self-hosted, windows]]

    runs-on: ${{ matrix.os }}

    env:
      LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
      LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Configure Persistent Paths (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $cacheRoot = "C:\LiveCap\Cache"
          
          # Ensure directories exist
          New-Item -ItemType Directory -Force -Path "$cacheRoot\uv" | Out-Null
          New-Item -ItemType Directory -Force -Path "$cacheRoot\models" | Out-Null
          New-Item -ItemType Directory -Force -Path "$cacheRoot\cache" | Out-Null
          New-Item -ItemType Directory -Force -Path "$cacheRoot\ffmpeg-bin" | Out-Null
          
          # Set Environment Variables
          "UV_CACHE_DIR=$cacheRoot\uv" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          "LIVECAP_CORE_MODELS_DIR=$cacheRoot\models" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          "LIVECAP_CORE_CACHE_DIR=$cacheRoot\cache" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          "LIVECAP_FFMPEG_BIN=$cacheRoot\ffmpeg-bin" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          
          Write-Host "Configured persistent paths at $cacheRoot"

      - name: Configure Persistent Paths (Linux)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          CACHE_ROOT="$HOME/LiveCap/Cache"
          
          # Ensure directories exist
          mkdir -p "$CACHE_ROOT/uv"
          mkdir -p "$CACHE_ROOT/models"
          mkdir -p "$CACHE_ROOT/cache"
          mkdir -p "$CACHE_ROOT/ffmpeg-bin"
          
          # Set Environment Variables
          echo "UV_CACHE_DIR=$CACHE_ROOT/uv" >> $GITHUB_ENV
          echo "LIVECAP_CORE_MODELS_DIR=$CACHE_ROOT/models" >> $GITHUB_ENV
          echo "LIVECAP_CORE_CACHE_DIR=$CACHE_ROOT/cache" >> $GITHUB_ENV
          echo "LIVECAP_FFMPEG_BIN=$CACHE_ROOT/ffmpeg-bin" >> $GITHUB_ENV
          
          echo "Configured persistent paths at $CACHE_ROOT"

      - name: Set up Python (Linux)
        if: runner.os == 'Linux'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Use preinstalled Python (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $python = Get-Command python3.12 | Select-Object -ExpandProperty Source
          if (-not $python) { throw "python3.12 not found on runner" }
          Write-Host "Using python at $python"
          "PYTHON_EXE=$python" | Out-File -FilePath $Env:GITHUB_ENV -Encoding utf8 -Append

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      # Restore UV_CACHE_DIR after setup-uv overwrites it with a temp path
      - name: Restore UV_CACHE_DIR (Linux)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          echo "UV_CACHE_DIR=$HOME/LiveCap/Cache/uv" >> $GITHUB_ENV
          echo "Restored UV_CACHE_DIR to $HOME/LiveCap/Cache/uv"

      - name: Restore UV_CACHE_DIR (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          "UV_CACHE_DIR=C:\LiveCap\Cache\uv" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          Write-Host "Restored UV_CACHE_DIR to C:\LiveCap\Cache\uv"

      # Removed actions/cache for ffmpeg-bin as we use persistent LIVECAP_FFMPEG_BIN

      - name: Check FFmpeg existence (Linux)
        if: runner.os == 'Linux'
        id: check-ffmpeg-linux
        shell: bash
        run: |
          if [ -f "$LIVECAP_FFMPEG_BIN/ffmpeg" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "FFmpeg found at $LIVECAP_FFMPEG_BIN"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "FFmpeg not found, triggering setup"
          fi

      - name: Check FFmpeg existence (Windows)
        if: runner.os == 'Windows'
        id: check-ffmpeg-windows
        shell: pwsh
        run: |
          if (Test-Path "$Env:LIVECAP_FFMPEG_BIN\ffmpeg.exe") {
            echo "exists=true" | Out-File -FilePath $Env:GITHUB_OUTPUT -Encoding utf8 -Append
            Write-Host "FFmpeg found at $Env:LIVECAP_FFMPEG_BIN"
          } else {
            echo "exists=false" | Out-File -FilePath $Env:GITHUB_OUTPUT -Encoding utf8 -Append
            Write-Host "FFmpeg not found, triggering setup"
          }

      - name: Setup LiveCap FFmpeg
        if: (runner.os == 'Linux' && steps.check-ffmpeg-linux.outputs.exists != 'true') || (runner.os == 'Windows' && steps.check-ffmpeg-windows.outputs.exists != 'true')
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: ${{ env.LIVECAP_FFMPEG_BIN }}

      - name: Sync dependencies (Linux)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          # Bypass lockfile sync
          rm -f uv.lock
          
          # Create venv and install dependencies manually
          uv venv
          # Install PyTorch from official index (cu124)
          uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
          # Install project dependencies
          uv pip install -e .[translation,dev,engines-torch,engines-nemo]
          # Remove conflicting cuDNN package
          uv pip uninstall nvidia-cudnn-cu12

      - name: Sync dependencies (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          # Reuse .venv if exists? No, for now keep clean slate but use cache
          # To optimize further, we could remove this Remove-Item line
          Remove-Item -Recurse -Force .venv -ErrorAction SilentlyContinue
          
          # Create venv explicitly
          uv python pin "$Env:PYTHON_EXE"
          uv venv
          
          # Add venv to PATH for subsequent steps
          echo "$PWD/.venv/Scripts" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
          
          # 1. Install CUDA-enabled PyTorch FIRST
          uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
          
          # 2. Install project dependencies using 'uv pip install'
          uv pip install -e .[translation,dev,engines-torch,engines-nemo]

      - name: Warm engine caches (GPU / self-hosted, Linux)
        if: runner.os == 'Linux'
        shell: bash
        # LIVECAP_FFMPEG_BIN is already set globally by Configure Persistent Paths
        run: |
          # Bypass lockfile sync by using python directly
          .venv/bin/python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          import gc
          import torch

          def warm(engine_type: str, device: str, lang: str) -> None:
              try:
                  cfg = get_default_config()
                  transcription = cfg["transcription"]
                  transcription["engine"] = engine_type
                  transcription["input_language"] = lang
                  engine = EngineFactory.create_engine(
                      engine_type=engine_type,
                      device=device,
                      config=cfg,
                  )
                  engine.load_model()
                  models_dir = engine.model_manager.get_models_dir(engine.engine_name)
                  print(f"[{engine_type}/{device}] cached at: {models_dir}")
                  # Cleanup to free VRAM for next engine
                  if hasattr(engine, 'cleanup'):
                      engine.cleanup()
                  del engine
              except Exception as e:
                  print(f"[{engine_type}/{device}] SKIP (warm-up failed): {e}")
              finally:
                  gc.collect()
                  if torch.cuda.is_available():
                      torch.cuda.empty_cache()

          # ReazonSpeech disabled on Linux GPU due to ABI compatibility issues with system libraries
          warm("whispers2t_base", "cuda", "en")
          warm("parakeet", "cuda", "en")
          warm("parakeet_ja", "cuda", "ja")
          warm("canary", "cuda", "en")
          # voxtral excluded: requires ~16GB VRAM (Linux GPU has 11.6GB)
          PY

      - name: Warm engine caches (GPU / self-hosted, Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        # LIVECAP_FFMPEG_BIN is already set globally by Configure Persistent Paths
        run: |
          $script = @"
          import os
          import sys
          
          # Monkey-patch os.uname for Windows to satisfy lhotse dependency
          # Note: Keep this logic in sync with tests/conftest.py
          if sys.platform == "win32" and not hasattr(os, "uname"):
              from collections import namedtuple
              UnameResult = namedtuple("UnameResult", ["sysname", "nodename", "release", "version", "machine"])
              def uname():
                  # Avoid platform.* calls that might recurse back to os.uname
                  return UnameResult(
                      sysname="Windows",
                      nodename=os.environ.get("COMPUTERNAME", "unknown"),
                      release=os.environ.get("OS", "unknown"),
                      version="10.0.xxxx",
                      machine=os.environ.get("PROCESSOR_ARCHITECTURE", "AMD64")
                  )
              os.uname = uname

          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config
          import gc
          import torch

          def warm(engine_type: str, device: str, lang: str) -> None:
              try:
                  cfg = get_default_config()
                  transcription = cfg["transcription"]
                  transcription["engine"] = engine_type
                  transcription["input_language"] = lang
                  engine = EngineFactory.create_engine(
                      engine_type=engine_type,
                      device=device,
                      config=cfg,
                  )
                  engine.load_model()
                  models_dir = engine.model_manager.get_models_dir(engine.engine_name)
                  print(f'[{engine_type}/{device}] cached at: {models_dir}')
                  # Cleanup to free VRAM for next engine
                  if hasattr(engine, 'cleanup'):
                      engine.cleanup()
                  del engine
              except Exception as e:
                  print(f'[{engine_type}/{device}] SKIP (warm-up failed): {e}')
              finally:
                  gc.collect()
                  if torch.cuda.is_available():
                      torch.cuda.empty_cache()

          warm('reazonspeech', 'cuda', 'ja')
          warm('whispers2t_base', 'cuda', 'en')
          warm('parakeet', 'cuda', 'en')
          warm('parakeet_ja', 'cuda', 'ja')
          warm('canary', 'cuda', 'en')
          warm('voxtral', 'cuda', 'en')
          "@
          
          $script | Out-File warmup.py -Encoding utf8
          # Use python directly
          python warmup.py

      - name: Run engine smoke tests (GPU / self-hosted, Linux)
        if: runner.os == 'Linux'
        shell: bash
        env:
          # LIVECAP_FFMPEG_BIN set globally
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          # Skip ReazonSpeech on Linux GPU due to ABI compatibility issues with system libraries
          # Bypass lockfile sync
          .venv/bin/python -m pytest tests/integration/engines -m "engine_smoke and gpu" -k "not reazonspeech" -v

      - name: Run engine smoke tests (GPU / self-hosted, Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        env:
          # LIVECAP_FFMPEG_BIN set globally
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          # Use python directly
          python -m pytest tests/integration/engines -m "engine_smoke and gpu" -v
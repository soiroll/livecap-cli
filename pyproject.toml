[build-system]
requires = ["setuptools>=69.0"]
build-backend = "setuptools.build_meta"

[project]
name = "livecap-cli"
version = "1.0.0.dev0"
description = "High-performance speech transcription CLI with multi-engine support."
readme = "README.md"
requires-python = ">=3.10,<3.13"
license = "AGPL-3.0-only"
maintainers = [
  { name = "PineLab" }
]
classifiers = [
  "Development Status :: 3 - Alpha",
  "Intended Audience :: Developers",
  "Programming Language :: Python",
  "Programming Language :: Python :: 3",
  "Programming Language :: Python :: 3.10",
  "Programming Language :: Python :: 3.11",
  "Programming Language :: Python :: 3.12",
  "Topic :: Multimedia :: Sound/Audio :: Speech"
]
authors = [
  { name = "Pine Lab" }
]
dependencies = [
  "appdirs>=1.4.4",
  "ffmpeg-python",
  "huggingface-hub>=0.34.0",
  "langcodes>=3.4.0",  # BCP-47 language code parsing for ASR engines
  "librosa",
  "moviepy",
  "numba>=0.55.0",  # Python 3.10+ support required
  "numpy",
  "onnxruntime",
  "pydub",
  "requests>=2.31",
  "scipy",
  "sounddevice",
  "soundfile",
  "sherpa-onnx>=1.12.17",  # matches Live_Cap_v3 requirement and includes stability fixes
  "tokenizers>=0.14.0",  # Python 3.10+ wheels required; pip resolver fix for whisper-s2t
  "optimum>=1.17.0",  # Proper metadata/wheels; pip resolver fix for whisper-s2t transitive dep
  "transformers>=4.36.0",  # Compatible with tokenizers>=0.14.0; pip resolver fix for whisper-s2t
  "ctranslate2>=3.24.0",  # Python 3.10+ wheels; pip resolver fix for whisper-s2t transitive dep
  "tqdm>=4.65",
  "whisper-s2t",
  # VAD backends (required for realtime transcription)
  # NOTE: TenVAD requires libc++ on Linux: sudo apt-get install libc++1
  "silero-vad>=5.1",
  "webrtcvad>=2.0.10",
  "ten-vad @ git+https://github.com/TEN-framework/ten-vad.git@a64b408d9ff89cd92bd0772ed99f9d58b7a005b1",
]
keywords = ["speech-to-text", "translation", "live captioning"]

license-files = ["LICENSE", "LICENSE-COMMERCIAL.md"]

[project.urls]
Homepage = "https://github.com/Mega-Gorilla/livecap-cli"
Source = "https://github.com/Mega-Gorilla/livecap-cli"
Issues = "https://github.com/Mega-Gorilla/livecap-cli/issues"
Documentation = "https://github.com/Mega-Gorilla/Live_Cap_v3/tree/main/docs"
Discord = "https://discord.gg/hdSV4hJR8Y"
Steam = "https://store.steampowered.com/app/3327370/"

[project.scripts]
livecap-cli = "livecap_cli.cli:main"

[project.optional-dependencies]
"engines-nemo" = [
  "Cython",
  "hydra-core",
  "matplotlib",  # Required by NeMo for visualization/logging
  "nemo-toolkit>=2.3.0",  # 2.1.0 has canary transcription bug (empty output)
  "nemo_toolkit[asr]>=2.3.0",
  "ml-dtypes>=0.5.0; python_version < '3.13'",
  "transformers>=4.57.0",  # Required for Voxtral (VoxtralForConditionalGeneration)
  "mistral-common[audio]>=1.8.1",  # Required for Voxtral audio processing
]
"engines-torch" = [
  "reazonspeech-k2-asr @ git+https://github.com/reazon-research/ReazonSpeech.git@9d80a30af1b5f456817db901a28ae462731b8157#subdirectory=pkg/k2-asr",
  "torch",
  "torchaudio",
  "torchvision",
]
"translation" = [
  "deep-translator",
]
"translation-local" = [
  "ctranslate2>=4.0.0",        # OPUS-MT inference engine
  "transformers>=4.40.0",      # Model loading & tokenizer
  # sentencepiece is auto-installed by transformers
]
"translation-riva" = [
  "transformers>=4.40.0",      # Riva-4B model loading & chat template
  "torch>=2.0.0",              # GPU inference
  "accelerate>=0.20.0",        # Model loading utilities
]
"dev" = [
  "pytest>=8.4",
]
"benchmark" = [
  # JaVAD for Japanese VAD benchmarking (other VAD backends are in default dependencies)
  "javad",
  # Metrics and reporting
  "jiwer>=3.0",      # WER/CER calculation
  "tabulate>=0.9",   # Console table formatting
]
"optimization" = [
  # Bayesian optimization framework
  "optuna>=3.0",
  # Visualization (HTML reports with interactive charts)
  "plotly>=5.0",
  # Includes benchmark dependencies
  "jiwer>=3.0",
  # JaVAD for optimization comparison
  "javad",
]
# Meta extras for easy installation
"recommended" = [
  "deep-translator",  # Google translation
]
"all" = [
  # All engines
  "Cython",
  "hydra-core",
  "matplotlib",
  "nemo-toolkit>=2.3.0",
  "nemo_toolkit[asr]>=2.3.0",
  "ml-dtypes>=0.5.0; python_version < '3.13'",
  "transformers>=4.57.0",
  "mistral-common[audio]>=1.8.1",
  "reazonspeech-k2-asr @ git+https://github.com/reazon-research/ReazonSpeech.git@9d80a30af1b5f456817db901a28ae462731b8157#subdirectory=pkg/k2-asr",
  "torch",
  "torchaudio",
  "torchvision",
  # All translation
  "deep-translator",
  "ctranslate2>=4.0.0",
  "accelerate>=0.20.0",
  # Benchmark and optimization
  "javad",
  "jiwer>=3.0",
  "tabulate>=0.9",
  "optuna>=3.0",
  "plotly>=5.0",
]

[tool.setuptools.packages.find]
where = ["."]
include = ["livecap_cli*", "benchmarks*"]

[tool.pytest.ini_options]
markers = [
  "engine_smoke: end-to-end engine smoke tests with real audio fixtures",
  "gpu: tests that require a CUDA-capable environment",
  "realtime_e2e: E2E tests for realtime transcription (requires LIVECAP_ENABLE_REALTIME_E2E=1)",
  "network: tests that require network access (opt-in via -m network)",
  "slow: slow tests that download/load models (opt-in via -m slow)",
]
# Default: skip network and slow tests (opt-in via: pytest -m 'network or slow')
addopts = "-m 'not network and not slow'"
